"""
Twitter Auto-Monitor Script
Her saat Ã§alÄ±ÅŸÄ±p @tekyolfener tweetlerini analiz eder
"""
import json
import os
import re
import requests
from datetime import datetime, timezone, timedelta
from pathlib import Path

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

# Takip edilecek hesaplar (TWITTER_ACCOUNTS env var'dan virgÃ¼lle ayrÄ±lmÄ±ÅŸ)
DEFAULT_ACCOUNTS = "tekyolfener,FenerGlobalOrg,Fenereditor,bbosports,ajansfenercom"
ACCOUNTS = os.environ.get("TWITTER_ACCOUNTS", DEFAULT_ACCOUNTS).split(",")
ACCOUNTS = [a.strip() for a in ACCOUNTS if a.strip()]

# Dosya yollarÄ±
ARCHIVE_FILE = Path(__file__).parent / "tweets_archive.json"

def fetch_tweets(username: str) -> list:
    """Twitter Syndication API ile tweetleri Ã§ek"""
    url = f"https://syndication.twitter.com/srv/timeline-profile/screen-name/{username}"
    
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        
        # HTML response'dan JSON'u Ã§Ä±kar
        html = response.text
        
        # __NEXT_DATA__ script tag'inden JSON'u bul
        match = re.search(r'<script id="__NEXT_DATA__" type="application/json">(.+?)</script>', html)
        if not match:
            print(f"Could not find tweet data for @{username}")
            return []
        
        data = json.loads(match.group(1))
        entries = data.get("props", {}).get("pageProps", {}).get("timeline", {}).get("entries", [])
        
        tweets = []
        for entry in entries:
            if entry.get("type") == "tweet":
                tweet = entry.get("content", {}).get("tweet", {})
                tweets.append({
                    "id": tweet.get("id_str"),
                    "text": tweet.get("full_text", tweet.get("text", "")),
                    "created_at": tweet.get("created_at"),
                    "username": username,
                    "likes": tweet.get("favorite_count", 0),
                    "retweets": tweet.get("retweet_count", 0),
                    "url": f"https://x.com/{username}/status/{tweet.get('id_str')}"
                })
        
        return tweets
        
    except Exception as e:
        print(f"Error fetching tweets for @{username}: {e}")
        return []

def filter_recent_tweets(tweets: list, hours: int = 1) -> list:
    """Son X saat iÃ§indeki tweetleri filtrele"""
    cutoff = datetime.now(timezone.utc) - timedelta(hours=hours)
    recent = []
    
    for tweet in tweets:
        try:
            # Twitter tarih formatÄ±: "Sat Feb 25 15:58:21 +0000 2023"
            created = datetime.strptime(tweet["created_at"], "%a %b %d %H:%M:%S %z %Y")
            if created > cutoff:
                tweet["created_parsed"] = created.isoformat()
                recent.append(tweet)
        except (ValueError, TypeError):
            continue
    
    return recent

def analyze_with_gemini(tweets: list) -> list:
    """Gemini ile haber deÄŸeri analizi ve taslak oluÅŸturma"""
    if not GEMINI_AVAILABLE or not os.environ.get("GEMINI_API_KEY"):
        print("Gemini not available, returning all tweets as-is")
        for tweet in tweets:
            tweet["is_newsworthy"] = True
            tweet["news_summary"] = tweet["text"][:200]
            tweet["draft"] = tweet["text"][:280]
        return tweets
    
    genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
    model = genai.GenerativeModel("gemini-2.0-flash")
    
    analyzed = []
    for tweet in tweets:
        prompt = f"""
Bu tweet'i analiz et ve haber taslaÄŸÄ± oluÅŸtur.

Tweet: {tweet['text']}
Kaynak: @{tweet['username']}

GÃ–REV:
1. Bu tweet haber deÄŸeri taÅŸÄ±yor mu? (transfer, maÃ§ sonucu, resmi aÃ§Ä±klama, Ã¶nemli geliÅŸme)
2. Haber deÄŸeri varsa, profesyonel bir haber taslaÄŸÄ± oluÅŸtur.

KURRALLAR:
- Maksimum 280 karakter
- Emoji KULLANMA
- Sonuna parantez iÃ§inde kaynak ekle: (@{tweet['username']})
- Ã–nemli haberlere baÅŸa #SONDAKÄ°KA | ekle

JSON formatÄ±nda yanÄ±t ver:
{{
  "is_newsworthy": true/false,
  "reason": "neden haber deÄŸeri var/yok",
  "draft": "hazÄ±r tweet taslaÄŸÄ± (max 280 karakter, kaynak dahil)"
}}
"""
        try:
            response = model.generate_content(prompt)
            text = response.text.strip().replace("```json", "").replace("```", "").strip()
            result = json.loads(text)
            tweet["is_newsworthy"] = result.get("is_newsworthy", False)
            tweet["analysis_reason"] = result.get("reason", "")
            tweet["draft"] = result.get("draft", f"{tweet['text'][:250]} (@{tweet['username']})")
            analyzed.append(tweet)
            print(f"   âœ“ @{tweet['username']}: {'Haber' if tweet['is_newsworthy'] else 'DeÄŸil'}")
        except Exception as e:
            print(f"   âœ— Analiz hatasÄ±: {e}")
            tweet["is_newsworthy"] = False
            tweet["draft"] = ""
            analyzed.append(tweet)
    
    return analyzed

def load_archive() -> dict:
    """Mevcut arÅŸivi yÃ¼kle"""
    if ARCHIVE_FILE.exists():
        try:
            with open(ARCHIVE_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except json.JSONDecodeError:
            pass
    return {"tweets": [], "last_updated": None}

def save_archive(archive: dict):
    """ArÅŸivi kaydet"""
    archive["last_updated"] = datetime.now(timezone.utc).isoformat()
    with open(ARCHIVE_FILE, "w", encoding="utf-8") as f:
        json.dump(archive, f, ensure_ascii=False, indent=2)

def main():
    print(f"ğŸ” Tweet Monitor baÅŸlatÄ±ldÄ±: {datetime.now(timezone.utc).isoformat()}")
    
    archive = load_archive()
    existing_ids = {t["id"] for t in archive["tweets"]}
    new_tweets = []
    
    for username in ACCOUNTS:
        print(f"\nğŸ“¡ @{username} taranÄ±yor...")
        tweets = fetch_tweets(username)
        print(f"   Toplam {len(tweets)} tweet bulundu")
        
        # Son 1 saat filtresi - sadece yeni tweetler
        recent = filter_recent_tweets(tweets, hours=1)
        print(f"   Son 1 saat: {len(recent)} tweet")
        
        # Yeni tweetleri filtrele
        for tweet in recent:
            if tweet["id"] not in existing_ids:
                new_tweets.append(tweet)
    
    print(f"\nğŸ†• {len(new_tweets)} yeni tweet bulundu")
    
    if new_tweets:
        # Gemini analizi
        analyzed = analyze_with_gemini(new_tweets)
        newsworthy = [t for t in analyzed if t.get("is_newsworthy")]
        print(f"ğŸ“° {len(newsworthy)} haber deÄŸeri taÅŸÄ±yan tweet")
        
        # ArÅŸive ekle
        archive["tweets"].extend(newsworthy)
        
        # Son 100 tweet tut
        archive["tweets"] = archive["tweets"][-100:]
        
        save_archive(archive)
        print(f"ğŸ’¾ ArÅŸiv gÃ¼ncellendi: {ARCHIVE_FILE}")
    else:
        print("â³ Yeni tweet yok")
    
    print("\nâœ… TamamlandÄ±")

if __name__ == "__main__":
    main()
